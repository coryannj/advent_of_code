import { Awaitable, ItemOfIterable } from "@kaciras/utilities/browser";
import { Profiler } from "./profiling.js";
import { TimeProfilerOptions } from "./time.js";
import { ValidateOptions } from "./validate.js";
import { ComplexityOptions } from "./complexity.js";
export type HookFn = () => Awaitable<unknown>;
type Workload = () => Awaitable<unknown>;
export declare class BenchCase {
    readonly name: string;
    /**
     * The workload function, should be called with iteration hooks.
     *
     * Always treat the iteration hooks and `fn` as a whole,
     * calling `fn` separately will result in undefined behavior.
     *
     * @see BenchCase.invoke
     */
    readonly fn: Workload;
    readonly beforeHooks: HookFn[];
    readonly afterHooks: HookFn[];
    /**
     * true if the case defined by `benchAsync`, false for `bench`.
     */
    readonly isAsync: boolean;
    /**
     * A unique number within a suite execution.
     * It is used to associate some objects with this case.
     */
    id?: number;
    constructor(scene: Scene, name: string, fn: Workload, isAsync: boolean);
    /**
     * Call the workload and each iteration hook once.
     *
     * The returned value is always awaited even if `isAsync` is false.
     */
    invoke(): Promise<any>;
    /**
     * Create an new benchmark case for the workload function,
     * and it has the same name & id with the original.
     *
     * `beforeHooks` and `afterHooks` can be added later.
     *
     * @param isAsync Indicates whether ESBench need to `await` for
     *                the return value of `fn` while measuring.
     * @param fn the new workload function.
     */
    derive(isAsync: boolean, fn: Workload): BenchCase;
}
export declare class Scene<P = any> {
    readonly teardownHooks: HookFn[];
    readonly beforeIterHooks: HookFn[];
    readonly afterIterHooks: HookFn[];
    readonly cases: BenchCase[];
    readonly params: P;
    private readonly include;
    constructor(params: P, include?: RegExp);
    /**
     * Register a callback to be called exactly once before each benchmark invocation.
     * It's not recommended to use this in microbenchmarks because it can spoil the results.
     */
    beforeIteration(fn: HookFn): void;
    /**
     * Register a callback to be called exactly once after each invocation.
     * It's not recommended to use this in microbenchmarks because it can spoil the results.
     */
    afterIteration(fn: HookFn): void;
    /**
     * Teardown function to run after all case in the scene are executed.
     */
    teardown(fn: HookFn): void;
    /**
     * Add a benchmark case to the scene, and consider an execution complete when `fn` returns.
     *
     * For asynchronous function, you may need to use `benchAsync` instead.
     *
     * @param name Name of the case
     * @param fn The workload function
     */
    bench(name: string, fn: Workload): void;
    /**
     * Add a benchmark case to the scene. If `fn` returns a Promise, it will be awaited.
     *
     * For synchronized function `bench` should be used to avoid the overhead of `await`.
     *
     * @param name Name of the case
     * @param fn The workload function
     */
    benchAsync(name: string, fn: Workload): void;
    private add;
}
export interface BaselineOptions {
    /**
     * Type of the baseline variable, can be one of:
     * - "Name", "Builder", "Executor"
     * - Any key of suite's `params` object.
     */
    type: string;
    /**
     * Case with variable value equals to this is the baseline.
     */
    value: unknown;
}
export type ParamsDef = Record<string, Iterable<unknown> | Record<string, unknown>>;
type SceneParams<T extends ParamsDef> = {
    -readonly [K in Exclude<keyof T, symbol>]: T[K] extends Iterable<unknown> ? ItemOfIterable<T[K]> : T[K][keyof T[K]];
};
export type ParamsAny = Record<string, any[] | Record<string, any>>;
type Empty = Record<string, undefined[]>;
export interface BenchmarkSuite<T extends ParamsDef = ParamsAny> {
    /**
     * Setup each scene, add your benchmark cases.
     */
    setup: (scene: Scene<SceneParams<T>>) => Awaitable<void>;
    /**
     * Runs a function before running the suite.
     */
    beforeAll?: HookFn;
    /**
     * Runs a function after the suite has finished running.
     */
    afterAll?: HookFn;
    /**
     * Add more profilers for the suite, falsy values are ignored.
     *
     * @see https://esbench.vercel.app/api/profiler
     */
    profilers?: Array<Profiler | false | undefined>;
    /**
     * Measure the running time of the benchmark function.
     * true is equivalent to not specifying the option and will always choose the default value.
     *
     * @default true
     * @see https://esbench.vercel.app/guide/time-profiler
     */
    timing?: boolean | TimeProfilerOptions;
    /**
     * Checks if it is possible to run your benchmarks.
     * If set, all scenes and their cases will be run once to ensure no exceptions.
     *
     * Additional checks can be configured in the options.
     *
     * @see https://esbench.vercel.app/guide/validation
     */
    validate?: ValidateOptions<SceneParams<T>>;
    /**
     * Calculate asymptotic complexity of benchmark cases.
     *
     * @see https://esbench.vercel.app/guide/complexity
     */
    complexity?: ComplexityOptions<T>;
    /**
     * you can specify set of values. As a result, you will get results
     * for each combination of params values.
     *
     * If not specified, or it is an empty object, the suite will have one scene with empty params.
     *
     * The keys for the suite parameters must be the same under all toolchains.
     *
     * @see https://esbench.vercel.app/guide/parameterization
     */
    params?: T;
    /**
     * Mark a variable as a baseline to scale your results.
     *
     * @example
     * // The result with baseline: { type: "Name", value: "For-index" }
     * | No. |         Name |      time | time.ratio |
     * | --: | -----------: | --------: | ---------: |
     * |   0 |    For-index |  11.39 us |   baseline |
     * |   1 |       For-of |  27.36 us |      2.40x |
     * |   2 | Array.reduce |   1.99 us |      0.17x |
     *
     * @see https://esbench.vercel.app/guide/comparison#baseline
     */
    baseline?: BaselineOptions;
}
export type UserSuite<T extends ParamsDef = ParamsAny> = BenchmarkSuite<T> | BenchmarkSuite<Empty>["setup"];
/**
 * Type helper to mark the object as an ESBench suite.
 * IDE plugins also require it to find benchmark cases.
 */
export declare const defineSuite: <const T extends ParamsDef = Empty>(suite: UserSuite<T>) => UserSuite<T>;
export type Entries<T = unknown> = Array<[string, T[]]>;
export type NormalizedSuite = Omit<BenchmarkSuite, "timing" | "params"> & {
    /**
     * Entries of params, for generating Cartesian product to create scenes.
     *
     * @example
     * // The params of user suite:
     * const symbol = Symbol("desc");
     * const input = {
     *     foo: { bool: true, text: "baz" },
     *     bar: [11, null, symbol],
     * }
     * // The params of NormalizedSuite:
     * const params = [
     *     ["foo", [true, "baz"]],
     *     ["bar", [11, null, symbol]],
     * ]
     */
    params: Entries;
    /**
     * Parallel array of `params`, with each value replaced by its display name.
     *
     * @example
     * // The params of user suite:
     * const symbol = Symbol("desc");
     * const input = {
     *     foo: { bool: true, text: "baz" },
     *     bar: [11, null, symbol],
     * }
     * // The paramNames:
     * const params = [
     *     ["foo", ["bool", "text"]],
     *     ["bar", ["11", "null", "Symbol(desc)"]],
     * ]
     */
    paramNames: Entries<string>;
    /**
     * Unlike `BenchmarkSuite`, the undefined means TimeProfiler disabled.
     */
    timing?: TimeProfilerOptions;
};
export declare function resolveParams(params: ParamsDef): readonly [Entries<unknown>, Entries<string>];
export declare function normalizeSuite(input: UserSuite): NormalizedSuite;
export {};
